{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits to Calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://towardsdatascience.com/building-a-handwritten-multi-digit-calculator-f03cf5028052"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels\n",
    "y = df[\"label\"]\n",
    "\n",
    "#Variables\n",
    "X = df.drop(labels = [\"label\"], axis = 1)\n",
    "\n",
    "#Delete to memory use\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pre Analising\n",
    "g = sns.countplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "X = X / 255.0\n",
    "\n",
    "#Reshape Dataset\n",
    "X = X.values.reshape(-1,28,28,1)\n",
    "\n",
    "#Enconding\n",
    "y = to_categorical(y, num_classes = 14)\n",
    "\n",
    "#Dividing in train and test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2,stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "#Creating model\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "#Layer: 1\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = \"Same\", activation = \"relu\", input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#Layer: 2\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "#fully connected layer and output\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(14, activation = \"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "#Optmizer\n",
    "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = 1e-08, decay=0.0 )\n",
    "\n",
    "#Model Compile\n",
    "model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "#Learining Rate\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = \"val_loss\", patience = 3, verbose = 1,\n",
    "                                            factor = 0.5, min_lr = 0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the image\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "#Training and prepare\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1914: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "761/761 [==============================] - 575s 719ms/step - loss: 0.6396 - accuracy: 0.8086 - val_loss: 0.0411 - val_accuracy: 0.9868\n",
      "Epoch 2/15\n",
      "761/761 [==============================] - 549s 722ms/step - loss: 0.0898 - accuracy: 0.9734 - val_loss: 0.0389 - val_accuracy: 0.9882\n",
      "Epoch 3/15\n",
      "761/761 [==============================] - 572s 751ms/step - loss: 0.0702 - accuracy: 0.9793 - val_loss: 0.0276 - val_accuracy: 0.9921\n",
      "Epoch 4/15\n",
      "761/761 [==============================] - 554s 728ms/step - loss: 0.0587 - accuracy: 0.9833 - val_loss: 0.0357 - val_accuracy: 0.9896\n",
      "Epoch 5/15\n",
      "761/761 [==============================] - 579s 761ms/step - loss: 0.0545 - accuracy: 0.9837 - val_loss: 0.0346 - val_accuracy: 0.9915\n",
      "Epoch 6/15\n",
      "761/761 [==============================] - 554s 728ms/step - loss: 0.0564 - accuracy: 0.9850 - val_loss: 0.0263 - val_accuracy: 0.9924\n",
      "Epoch 7/15\n",
      "761/761 [==============================] - 552s 726ms/step - loss: 0.0546 - accuracy: 0.9844 - val_loss: 0.0324 - val_accuracy: 0.9926\n",
      "Epoch 8/15\n",
      "761/761 [==============================] - 549s 722ms/step - loss: 0.0531 - accuracy: 0.9850 - val_loss: 0.0606 - val_accuracy: 0.9841\n",
      "Epoch 9/15\n",
      "761/761 [==============================] - 553s 726ms/step - loss: 0.0538 - accuracy: 0.9864 - val_loss: 0.0350 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/15\n",
      "761/761 [==============================] - 541s 711ms/step - loss: 0.0409 - accuracy: 0.9890 - val_loss: 0.0364 - val_accuracy: 0.9930\n",
      "Epoch 11/15\n",
      "761/761 [==============================] - 567s 745ms/step - loss: 0.0376 - accuracy: 0.9902 - val_loss: 0.0320 - val_accuracy: 0.9937\n",
      "Epoch 12/15\n",
      "761/761 [==============================] - 552s 726ms/step - loss: 0.0417 - accuracy: 0.9890 - val_loss: 0.0267 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/15\n",
      "761/761 [==============================] - 548s 720ms/step - loss: 0.0329 - accuracy: 0.9904 - val_loss: 0.0290 - val_accuracy: 0.9924\n",
      "Epoch 14/15\n",
      "761/761 [==============================] - 545s 717ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.0252 - val_accuracy: 0.9942\n",
      "Epoch 15/15\n",
      "761/761 [==============================] - 533s 700ms/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 0.0441 - val_accuracy: 0.9923\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "epochs = 15\n",
    "batch_size = 90\n",
    "\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, #An epoch is an iteration over the entire x and y data provided\n",
    "                              validation_data = (X_val,y_val), #Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                              verbose = 1, #output\n",
    "                              steps_per_epoch=X_train.shape[0] // batch_size,  # Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch.\n",
    "                              callbacks=[learning_rate_reduction]                            \n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from itertools import groupby\n",
    "\n",
    "\n",
    "def predict(img=\"output.png\"):\n",
    "    #loading image\n",
    "    image = Image.open(img).convert(\"L\")\n",
    "    \n",
    "    \n",
    "    #Pre processing\n",
    "    w = image.size[0]\n",
    "    h = image.size[1]\n",
    "    r = w / h # aspect ratio\n",
    "    new_w = int(r * 28)\n",
    "    new_h = 28\n",
    "    new_image = image.resize((new_w, new_h))\n",
    "\n",
    "    #converting to a numpy array\n",
    "    new_image_arr = np.array(new_image)\n",
    "\n",
    "    #inverting the image to make background = 0\n",
    "    new_inv_image_arr = 255 - new_image_arr\n",
    "\n",
    "    #rescaling the image\n",
    "    final_image_arr = new_inv_image_arr / 255.0\n",
    "\n",
    "    #splitting image array into individual element arrays using non zero columns\n",
    "    m = final_image_arr.any(0)\n",
    "    out = [final_image_arr[:,[*g]] for k, g in groupby(np.arange(len(m)), lambda x: m[x] != 0) if k]\n",
    "\n",
    "\n",
    "    '''\n",
    "    iterating through the element arrays to resize them to match input \n",
    "    criteria of the model = [mini_batch_size, height, width, channels]\n",
    "    '''\n",
    "    num_of_elements = len(out)\n",
    "    elements_list = []\n",
    "    for x in range(0, num_of_elements):\n",
    "        img = out[x]\n",
    "\n",
    "        #adding 0 value columns as fillers\n",
    "        width = img.shape[1]\n",
    "        filler = (final_image_arr.shape[0] - width) / 2\n",
    "\n",
    "        if filler.is_integer() == False:    #odd number of filler columns\n",
    "            filler_l = int(filler)\n",
    "            filler_r = int(filler) + 1\n",
    "        else:                               #even number of filler columns\n",
    "            filler_l = int(filler)\n",
    "            filler_r = int(filler)\n",
    "\n",
    "        arr_l = np.zeros((final_image_arr.shape[0], filler_l)) #left fillers\n",
    "        arr_r = np.zeros((final_image_arr.shape[0], filler_r)) #right fillers\n",
    "\n",
    "        #concatinating the left and right fillers\n",
    "        help_ = np.concatenate((arr_l, img), axis= 1)\n",
    "        element_arr = np.concatenate((help_, arr_r), axis= 1)\n",
    "\n",
    "        element_arr.resize(28, 28, 1) #resize array 2d to 3d\n",
    "        #storing all elements in a list\n",
    "        elements_list.append(element_arr)\n",
    "    elements_array = np.array(elements_list)\n",
    "    \n",
    "    #reshaping to fit model input criteria'\n",
    "    elements_array = elements_array.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    #predicting using the created model'\n",
    "    model = keras.models.load_model(\"model.h5\")\n",
    "    elements_pred =  model.predict(elements_array)\n",
    "    elements_pred = np.argmax(elements_pred, axis = 1)\n",
    "    return elements_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_pred = predict(\"output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid predicted expression!!\n",
      "Following is the predicted expression:\n",
      " * 1\n"
     ]
    }
   ],
   "source": [
    "def math_expression_generator(arr):\n",
    "    \n",
    "    op = {\n",
    "              10,   # = \"/\"\n",
    "              11,   # = \"+\"\n",
    "              12,   # = \"-\"\n",
    "              13    # = \"*\"\n",
    "                  }   \n",
    "    \n",
    "    m_exp = []\n",
    "    temp = []\n",
    "        \n",
    "    #creating a list separating all elements\n",
    "    for item in arr:\n",
    "        if item not in op:\n",
    "            temp.append(item)\n",
    "        else:\n",
    "            m_exp.append(temp)\n",
    "            m_exp.append(item)\n",
    "            temp = []\n",
    "    if temp:\n",
    "        m_exp.append(temp)\n",
    "        \n",
    "    #converting the elements to numbers and operators\n",
    "    i = 0\n",
    "    num = 0\n",
    "    for item in m_exp:\n",
    "        if type(item) == list:\n",
    "            if not item:\n",
    "                m_exp[i] = \"\"\n",
    "                i = i + 1\n",
    "            else:\n",
    "                num_len = len(item)\n",
    "                for digit in item:\n",
    "                    num_len = num_len - 1\n",
    "                    num = num + ((10 ** num_len) * digit)\n",
    "                m_exp[i] = str(num)\n",
    "                num = 0\n",
    "                i = i + 1\n",
    "        else:\n",
    "            m_exp[i] = str(item)\n",
    "            m_exp[i] = m_exp[i].replace(\"10\",\"/\")\n",
    "            m_exp[i] = m_exp[i].replace(\"11\",\"+\")\n",
    "            m_exp[i] = m_exp[i].replace(\"12\",\"-\")\n",
    "            m_exp[i] = m_exp[i].replace(\"13\",\"*\")\n",
    "            \n",
    "            i = i + 1\n",
    "    \n",
    "    \n",
    "    #joining the list of strings to create the mathematical expression'\n",
    "    separator = ' '\n",
    "    m_exp_str = separator.join(m_exp)\n",
    "    \n",
    "    return (m_exp_str)\n",
    "\n",
    "#creating the mathematical expression'\n",
    "m_exp_str = math_expression_generator(elements_pred)\n",
    "\n",
    "#calculating the mathematical expression using eval()'\n",
    "while True:\n",
    "    try:\n",
    "        answer = eval(m_exp_str)    #evaluating the answer\n",
    "        answer = round(answer, 2)\n",
    "        equation  = m_exp_str + \" = \" + str(answer)\n",
    "        print(equation)   #printing the equation\n",
    "        break\n",
    "\n",
    "    except SyntaxError:\n",
    "        print(\"Invalid predicted expression!!\")\n",
    "        print(\"Following is the predicted expression:\")\n",
    "        print(m_exp_str)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
